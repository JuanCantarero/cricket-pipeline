# ğŸ¦— Real-Time Cricket Detection on Raspberry Pi

This project uses a Raspberry Pi equipped with the official Pi Camera and a custom-trained YOLOv8 nano model to detect crickets in real time. It leverages picamera2, OpenCV, and the ultralytics library to capture video frames, run inference, and display bounding boxes over detected insects.
After detection, a mechanical flipper armâ€”similar to those found in pinball machinesâ€”is triggered to sort the crickets into two separate boxes based on their predicted sex (male or female).

---

## ğŸš€ Features

- ğŸ§  Real-time object detection using YOLOv8 nano 
- ğŸ¥ Seamless integration with the official Raspberry Pi Camera using `picamera2`  
- ğŸ’¡ Minimal dependencies â€” optimized for Raspberry Pi OS (Bookworm or later)  
- ğŸ Clean, modular Python code, easy to modify or extend  

---

## ğŸ–¥ï¸ Requirements & Installation

On the Raspberry Pi:  
Install system dependencies, create a virtual environment, and install required Python packages:

```bash
sudo apt update
sudo apt install -y python3-picamera2

python3 -m venv --system-site-packages ~/yoloenv
source ~/yoloenv/bin/activate
pip install ultralytics opencv-python
```

---

## ğŸ§  Model

The model used in this project was trained with Ultralytics YOLOv8 nano on a custom dataset of crickets.  
You can explore and download the dataset from Roboflow:

ğŸ”— **[Cricket Detection Dataset on Roboflow](https://universe.roboflow.com/cricket-sex-classification/auto-cricket)**

If you'd like to use your own data, check out the [Ultralytics training guide](https://docs.ultralytics.com).

Example model path:

```
/home/pi/Desktop/crickets/train2/weights/best.pt
```

---

## â–¶ï¸ Run the Detector

From your project folder:

```bash
source ~/yoloenv/bin/activate
python run_model.py
```

Exit detection by pressing **`q`**.

---

## ğŸ“‚ Project Structure

```
cricket-pipeline/
â”œâ”€â”€ model/
â”‚   â””â”€â”€ results/
â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ weights/
â”‚       â””â”€â”€ best.pt
â”‚       â””â”€â”€ last.pt
â”œâ”€â”€ training/
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ raspberry/
â”‚   â””â”€â”€ real_time_inference.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ cricket_demo.gif # Optional demo animation
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Troubleshooting

- âŒ **No frame captured** â†’ Ensure the camera is connected and enabled via `raspi-config`  
- âŒ **Qt plugin error** â†’ Use `Preview.NULL` instead of `Preview.QTGL`  
- âŒ **â€œExpected 3 channels, got 4â€** â†’ Add `frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2RGB)` before inference  

---

## ğŸ‘¤ Author

This project was developed by **Juan Cantarero**  
**Supervisor:** Dr. Matthew Smith  
Illinois Institute of Technology â€“ Master's in Artificial Intelligence                      
Universidad Politecnica de Madrid â€“ Master's in Industrial Engineering

---

## ğŸ“œ License

This project is publicly available under the [Creative Commons Attribution 4.0 International (CC BY 4.0) License](https://creativecommons.org/licenses/by/4.0/).

You are free to **use, share, and adapt** the material for any purpose, including commercial use, as long as you provide **appropriate credit**.

